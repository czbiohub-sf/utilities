{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change cell names in S3 and move to new S3 bucket\n",
    "\n",
    "A notebook for renaming a bunch of cells. You need to run this notebook in an environment with the `utilities` repo installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities.s3_util as s3u # importing this module of functions for working with s3\n",
    "\n",
    "import os # importing this to work with filenames\n",
    "\n",
    "from collections import Counter # for counting things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to get a list of all of the files we want to rename...depending on where they are that might be easy or hard.\n",
    "\n",
    "The function `s3u.get_files` takes a bucket name (e.g. `czb-seqbot`) and a **prefix** (e.g. `fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley`) and returns a generator of all the file names under that path. You can further filter them by matching against the extension or something else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4216"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastq_files = [\n",
    "    fn for fn in s3u.get_files(\n",
    "        bucket='czb-seqbot', \n",
    "        prefix='fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley'\n",
    "    )\n",
    "    if fn.endswith('.fastq.gz')\n",
    "]\n",
    "len(fastq_files) # how many files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/A10_B009246_S10_R1_001.fastq.gz',\n",
       " 'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/D5_B009315_S245_R1_001.fastq.gz',\n",
       " 'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/H21_B009320_S225_R1_001.fastq.gz',\n",
       " 'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/L18_B009469_S102_R1_001.fastq.gz',\n",
       " 'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/P14_B009247_S158_R1_001.fastq.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastq_files[::1000] # look at the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A10_B009246_S10_R1_001.fastq.gz',\n",
       " 'D5_B009315_S245_R1_001.fastq.gz',\n",
       " 'H21_B009320_S225_R1_001.fastq.gz',\n",
       " 'L18_B009469_S102_R1_001.fastq.gz',\n",
       " 'P14_B009247_S158_R1_001.fastq.gz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get just the basename (i.e. no folders)\n",
    "base_fns = [os.path.basename(fn) for fn in fastq_files]\n",
    "\n",
    "base_fns[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 4216})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# everything has the same number of underscores?\n",
    "# it's good to check this instead of assuming, because\n",
    "# we use this to grab the plate name\n",
    "Counter(fn.count('_') for fn in base_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'B009246': 702,\n",
       "         'B009247': 704,\n",
       "         'B009315': 702,\n",
       "         'B009319': 702,\n",
       "         'B009320': 702,\n",
       "         'B009469': 704})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the plate names, since we know it's always after the first underscore\n",
    "Counter(fn.split('_')[1] for fn in base_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702 702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/A10_B009246_S10_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/C16_B009246_S64_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/E21_B009246_S117_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/G6_B009246_S150_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/J12_B009246_S228_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/L19_B009246_S283_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/N3_B009246_S15_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/P9_B009246_S69_R1_001.fastq.gz'],\n",
       " ['fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/A10_B??????_S10_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/C16_B??????_S64_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/E21_B??????_S117_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/G6_B??????_S150_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/J12_B??????_S228_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/L19_B??????_S283_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/N3_B??????_S15_R1_001.fastq.gz',\n",
       "  'fastqs/181120_A00111_0230_BHGLJGDMXX/rawdata/Ashley/P9_B??????_S69_R1_001.fastq.gz'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the files with a given plate name\n",
    "old_names = [fn for fn in fastq_files if fn.find('_B009246_') > -1]\n",
    "\n",
    "# just using str.replace to rename the plates\n",
    "new_names = [fn.replace('_B009246_', '_B??????_') for fn in old_names]\n",
    "\n",
    "print(len(old_names), len(new_names))\n",
    "old_names[::100], new_names[::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `s3u.copy_files` takes five arguments:\n",
    "  \n",
    "  - `src_list` is the list of the files you want to copy, including the full path\n",
    "  - `dest_list` is their new names, in the same order as the source\n",
    "  - `b` is the bucket for the original files\n",
    "  - `nb` is the bucket for the new copies (you can just use the same bucket)\n",
    "  - `n_proc` tells the function how many processes to run&mdash;the copying doesn't really use your CPU much, so you can set this to 2-4 times the number of CPUs on your machine to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3u.copy_files(old_names, new_names, b='czb-seqbot', nb='czb-seqbot', n_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could take this opportunity to move the files into your own bucket, if you like\n",
    "# just need to change `nb` to `darmanis-group` after changing the path of the destination files\n",
    "new_names2 = [\n",
    "    os.path.join('some/path/inside/darmanis-group/', os.path.basename(fn))\n",
    "    for fn in new_names\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `s3u.remove_files` will delete things from S3, so it's pretty dangerous. Also it might not let you do this depending on where in S3 you are trying to delete from. It takes four arguments:\n",
    "\n",
    " - `file_list` is the list of files to delete (including path but not bucket)\n",
    " - `b` is the bucket to delete from\n",
    " - `really` is just a flag to make sure you're thinking about this, must be `True` to delete\n",
    " - `n_proc` is similar to above&mdash;you can use more processes to speed this up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the old versions of these files\n",
    "s3u.remove_files(old_names, b='czb-seqbot', really=True, n_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could rerun this a few times to rename different sets of plates, or you could rewrite it into a loop to do it all in one go."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:utilities]",
   "language": "python",
   "name": "conda-env-utilities-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
